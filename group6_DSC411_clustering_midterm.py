"""This is group 6 submission for DSC 411 Clustring Midterm Project
Team members are:
Murtadha Almakki
Eric Jackman
Quan Pham
"""

# importing libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import normalize
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt


# takes any pandas dataframe and converts all columns containing categorical data to numeric data
def convert_df_to_numeric(df):
	for col in df.columns:
		if df[col].dtype == 'object':
			df[col] = df[col].astype('category')
			df[col] = df[col].cat.codes


# calculating silhouette coefficient to find optimal k value
def silhouette_coefficient(X, labels):
	size = len(X)  # number of rows
	distance_matrix = np.zeros((size, size))  # create a matrix to store euclidean distances between all the elements

	# assign euclidean distance in the matrix which is square root of the sum of squared differences
	for i in range(0, size):
		for j in range(0, size):
			distance_matrix[i][j] = np.sqrt(np.sum((X[i] - X[j]) ** 2))

	silhouette = [0] * size  # create empty list with size of number of rows
	for i in range(0, size):
		# using conditional to check for columns who have same clusters
		index = np.where(labels == labels[i])[0]
		# calculate the average distance between points from same cluster
		a = np.sum(distance_matrix[i, index]) / (len(index) - 1)

		# calculate b as average distance between the clusters
		b = np.inf  # first assign as infinity if no conditions met
		for j in range(0, size):
			# using if conditional to check for columns who have different clusters
			if labels[j] != labels[i]:
				index = np.where(labels == labels[j])[0]
				cell = np.sum(distance_matrix[i, index]) / len(index)  # sum of distances divede by legnth
				if cell < b:
					b = cell

		# mathmatical formula for Silhouette score
		silhouette[i] = (b - a) / max(a, b)

	return np.mean(silhouette)


# returns the optimal k value determined by the silhouette coefficient
def get_optimal_k(X):
	# compute the Silhouette Coefficient for each K value
	k_values = range(2, 10)
	silhouette_scores = []
	for k in k_values:
		kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)
		labels = kmeans.fit_predict(X)
		silhouette_scores.append(silhouette_coefficient(X, labels))
	# In large files the function excute slower than silhouette_score from sklearn but will still return same results

	# plot the Silhouette Coefficients for each K value
	plt.plot(k_values, silhouette_scores)
	plt.xlabel('Number of clusters, K')
	plt.ylabel('Silhouette Coefficient')
	plt.show()

	# find the optimal K value
	optimal_k = k_values[np.argmax(silhouette_scores)]
	print('Optimal number of clusters:', optimal_k)

	return optimal_k


# performs bisecting k-means and returns a list of centroids
def bisecting_kmeans(k, X):
	num_clusters = 1  # initialize current number of clusters
	all_centroids = []  # clusters generated by bisecting kmeans

	while num_clusters < k:
		# perform kmeans with k=2
		kmeans = KMeans(n_clusters=2, n_init=10).fit(X)
		centroids = kmeans.cluster_centers_

		# calculate sse for the two clusters
		sse = [0, 0]
		for x, cluster in zip(X, kmeans.labels_):
			sse[cluster] += np.square(x - centroids[cluster]).sum()

		# determine next cluster to be split
		next_cluster_index = np.argmax(sse, axis=0)
		new_X = X[kmeans.labels_ == next_cluster_index]
		X = new_X

		# add new centroids to list
		if num_clusters == k - 1:
			all_centroids.append(centroids[0].tolist())
			all_centroids.append(centroids[1].tolist())
		else:
			all_centroids.append(centroids[next_cluster_index].tolist())

		num_clusters += 1

	return all_centroids


if __name__ == "__main__":
	# import data
	df = pd.read_csv(input('Enter path to dataset: '))

	# pre-process data
	df.replace("?", np.nan, inplace=True)
	df.dropna(inplace=True)
	convert_df_to_numeric(df)
	norm_array = normalize(df)
	df = pd.DataFrame(norm_array)
	X = df.iloc[:, :-1].values

	# get optimal k value
	optimal_k = get_optimal_k(X)

	# perform bisecting k-means with the optimal K value to get initial centers for k-means
	init_centers = np.array(bisecting_kmeans(optimal_k, X))

	# perform k-means with the optimal K value and using initial centers
	kmeans = KMeans(n_clusters=optimal_k, init=init_centers, n_init=1)
	labels = kmeans.fit_predict(X)
	centroids = kmeans.cluster_centers_
	SSE = kmeans.inertia_
	print('Centroids:', centroids)
	print('SSE:', SSE)

	# add cluster assignments to the original dataset
	df['Cluster'] = labels

	# plot the data in 3D using the first 3 features
	fig = plt.figure()
	ax = fig.add_subplot(111, projection='3d')
	colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'w']
	for i in range(optimal_k):
		ax.scatter(X[labels == i, 0], X[labels == i, 1], X[labels == i, 2], c=colors[i], label='Cluster ' + str(i + 1))
	ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], s=200, marker='*', c='k', label='Centroids')
	ax.set_xlabel('Feature 1')
	ax.set_ylabel('Feature 2')
	ax.set_zlabel('Feature 3')
	plt.legend()
	plt.show()

	# print the original dataset with cluster assignments
	print(df)
